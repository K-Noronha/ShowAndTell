{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='darkcyan'> Recommendation System for Connecting Like-Minded Users </font> \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are employing a content-based approach to build a recommendation system to recommend other users to a user with whom he/she can collaborate with.\n",
    "\n",
    "We will be using user's profile, comments and posts liked to come up with recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import sqlite3\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For Natural Language Processing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# For scaling the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# For calculating cosine simiarity\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### <font color='darkcyan'> Selecting features for building the recommendation system </font> \n",
    "\n",
    "\n",
    "These will be stored in the database `user`.\n",
    "\n",
    "| Column | Remarks                                            |\n",
    "|:-------|:---------------------------------------------------|\n",
    "|user_id|Unique identifier for the users|\n",
    "|user_name|Name of the user|\n",
    "|profile_interest|This is a non-numeric column. It provides information on the user profile and interests|\n",
    "|visual_art|This is a dummy variabe. 0 if not participated in this category, 1 if yes|\n",
    "|cooking|This is a dummy variabe. 0 if not participated in this category, 1 if yes|\n",
    "|music|This is a dummy variabe. 0 if not participated in this category, 1 if yes|\n",
    "|poetry|This is a dummy variabe. 0 if not participated in this category, 1 if yes|\n",
    "|artsandcraft|This is a dummy variabe. 0 if not participated in this category, 1 if yes|\n",
    "|post_shared|The number of posts shared by a user. This is a numeric column.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect('user.db')\n",
    "\n",
    "myquery = \"SELECT * FROM user_info\"\n",
    "            \n",
    "user_df = pd.read_sql(myquery, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### <font color='darkcyan'> Extracting features from the interest column by using Natural Language Processing (NLP) </font> \n",
    "\n",
    "</br></br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import string\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "ENGLISH_STOP_WORDS = stopwords.words('english')\n",
    "\n",
    "# Defining a custom function for tokenizing \n",
    "\n",
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "def my_tokenizer(sentence):\n",
    "    \n",
    "    sentence = sentence.replace('\\n','')\n",
    "    \n",
    "     # Remove numbers\n",
    "    list_digit= ['0','1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    for digit in list_digit:\n",
    "        sentence = sentence.replace(digit,'')\n",
    "    \n",
    "    # Remove punctuation and set to lower case\n",
    "    for punctuation_mark in string.punctuation:\n",
    "        sentence = sentence.replace(punctuation_mark,'').lower()\n",
    "\n",
    "    # split sentence into words\n",
    "    listofwords = sentence.split(' ')\n",
    "    listofstemmed_words = []\n",
    "    \n",
    "        \n",
    "    # Remove stopwords and any tokens that are just empty strings\n",
    "    for word in listofwords:\n",
    "        if (not word in ENGLISH_STOP_WORDS) and (word!='') and (not word in REMOVE_WORDS):\n",
    "\n",
    "            # Stem words\n",
    "            stemmed_word = stemmer.stem(word)\n",
    "            listofstemmed_words.append(stemmed_word)\n",
    "\n",
    "    return listofstemmed_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building a basic tf-idf vector using the above created tokenizer function\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Instantiate the Vectorizer\n",
    "tfidf = TfidfVectorizer(tokenizer=my_tokenizer)\n",
    "\n",
    "# Fit the Vectorizer to the training data\n",
    "tfidf.fit(user_df['profile_interest'])\n",
    "\n",
    "# Transform the training data \n",
    "reviews_tfidf = tfidf.transform(user_df['profile_interest'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming our original dataframe using the tfidf vector\n",
    "\n",
    "tfidf_result = (reviews_tfidf).toarray()\n",
    "tfidf_df = pd.DataFrame(tfidf_result, columns = tfidf.get_feature_names())\n",
    "combined_df= pd.concat([final_reviews, user_df], axis=1)\n",
    "\n",
    "# Dropping the non-numerical columns to compute the cosine similarity\n",
    "final_df = combined_df.drop(['user_id', 'user_name', 'profile_interest' ], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are using the cosine similarity metrics to compute the similarity between the users and ultimately make recommendations. If we think of the various features of each user being a vector in a multi-dimensional space, this metric captures the orientation rather than the distance between the vectors. Mathematically, it measures the cosine of the angle between the two vectors. \n",
    "\n",
    "We will convert the similarity array into a dataframe with the index and column values as the restaurant name, and the row value will represent the cosine similarity between the column and the index restaurants. The diagonal value which will represent the cosine similarity between the restaurant themselves will be 1. the value will be between 0 (no similarity) and 1 (absolute similarity)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the cosine similarity between the restaurants\n",
    "similarity_score = cosine_similarity(final_df, final_df)\n",
    "\n",
    "# Converting the above array to similarity score\n",
    "sim = pd.DataFrame(similarity_score, columns=user_df['user_name'], index=user_df['user_name'])\n",
    "\n",
    "\n",
    "# Recommendation Function\n",
    "\n",
    "def user_recommendations(user_id):\n",
    "    \n",
    "    # Making a dataframe to hold the list of recommendations sorted by cosine similarity in descending order\n",
    "    recommended_users = pd.DataFrame(list((sim[user_id].sort_values(ascending=False)).index))\n",
    "    \n",
    "    recommended_users.columns = ['Recommended Users']\n",
    "    \n",
    "    \n",
    "    return recommended_users.head(3)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
